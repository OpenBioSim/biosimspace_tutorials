{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Binding Free Energy (RBFE) Network Tutorial - Analysis\n",
    "\n",
    "This Jupyter notebook is a tutorial on an analysis workflow for RBFE calculations using a Free Energy Perturbation (FEP) network with BioSimSpace, as well as the Freenrgworkflows and Cinnabar packages.\n",
    "\n",
    "This notebook includes core as well as <span style=\"color:teal\">extra</span> options. These extra sections are there to include some more functionality for when the concepts of these tutorials are applied to your own work.      \n",
    "\n",
    "**<span style=\"color:teal\">Reading Time:</span>**\n",
    "~ 30 mins\n",
    "\n",
    "### Maintainers\n",
    "- [Anna Herz -- @annamherz](https://github.com/annamherz)\n",
    "\n",
    "See [README.md](https://github.com/michellab/BioSimSpaceTutorials/blob/main/04_fep/README.md) for complete list of authors.\n",
    "\n",
    "### Prerequisites\n",
    " - Basic Python\n",
    " - Part 1 of this workshop (An Introduction to setting up alchemical free energy calculations)\n",
    "    - this should include basic knowledge of the principles behind RBFE\n",
    " - The 01_setup_rbfe notebook\n",
    "\n",
    "### Learning Objectives\n",
    " - Analyse and plot the results of an FEP pipeline setup using BSS.\n",
    "\n",
    "### Table of Contents\n",
    "1. [Analysing the edges of the Network](#intro)    \n",
    "    1.1 [Analysing repeats](#reps)     \n",
    "    1.2 [Experimental binding affinities](#exp)      \n",
    "    1.3 [Plotting](#plot)      \n",
    "2. [Analysing per Ligand](#lig)   \n",
    "    2.1 [Freenrgworkflows](#fwf)     \n",
    "    2.2 [Plotting](#plot2)    \n",
    "    2.3 [Statistical analysis](#stats)     \n",
    "    2.4 [Outliers](#outliers)  \n",
    "3. [Cinnabar](#cinnabar)   \n",
    "\n",
    "### Further reading for this topic\n",
    "- [LiveComs Best Practices for Alchemical Free Energy Calculations](https://livecomsjournal.org/index.php/livecoms/article/view/v2i1e18378).\n",
    "\n",
    "**<span style=\"color:black\">Jupyter Cheat Sheet</span>**\n",
    "- To run the currently highlighted cell and move focus to the next cell, hold <kbd>&#x21E7; Shift</kbd> and press <kbd>&#x23ce; Enter</kbd>;\n",
    "- To run the currently highlighted cell and keep focus in the same cell, hold <kbd>&#x21E7; ctrl</kbd> and press <kbd>&#x23ce; Enter</kbd>;\n",
    "- To get help for a specific function, place the cursor within the function's brackets, hold <kbd>&#x21E7; Shift</kbd>, and press <kbd>&#x21E5; Tab</kbd>;\n",
    "- You can find the full documentation at [biosimspace.org](https://biosimspace.org).\n",
    "\n",
    "You can use `!` to access terminal commands: e.g. `! head -n 20 myfilename.dat` will display the first 20 lines of a file. \n",
    "\n",
    "\n",
    "### Exercises\n",
    "Exercises are announced using an alert alert-success box in this way:\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Exercise 1.1: Write a function that computes bond lengths:</b>\n",
    "</div>\n",
    "and followed by an incomplete cell. All exercises should be numbered. \n",
    "Missing parts are indicated by:\n",
    "\n",
    "```python\n",
    "#FIXME\n",
    "```\n",
    "These are included whilst running through the workshops and also in dedicated sections.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import BioSimSpace as BSS\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem as sem\n",
    "\n",
    "# define all the folder locations\n",
    "main_folder = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tutorial import download\n",
    "download(\"02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Analysing the edges of the Network\n",
    "<a id=\"intro\"></a>\n",
    "\n",
    "Once we have obtained our results, we want to analyse them. The basics of this analysis using `BSS.FreeEnergy.Relative.analyse()` for both MBAR and TI, as well as plotting overlap matrices, have already been covered in the introduction to alchemistry part of this workshop.\n",
    "\n",
    "In this part, we will look at how to carry out a large scale network analysis. As it would take some time to run the analysis for each perturbation, the [runs from this paper](https://chemrxiv.org/engage/chemrxiv/article-details/62ec4b0eadfd35eddd272954) have already been analysed using BSS to give the MBAR RBFE result and error in a csv file format. It is best practice to run repeats of the simulations, which is why there are multiple results files, one for each repeat. The files 'analysis/repeat_{r}_tyk2.csv' contain the results for this 'analysis/network_full.dat'. These runs are from a very large network, with some different ligands than we used for the first part of this RBFE tutorial. This is included incase you want to create a different network and analyse how the output changes based on the edges chosen. However, in this tutorial we will not be analysing this whole large network. We have a different network file to describe the inital network we want to consider, generated using LOMAP, in 'analysis/network.dat'. This uses the ligands from 'inputs/ligands/analysis_ligands'.\n",
    "\n",
    "There is also a csv file with the experimental results for these ligands. In cases where experimental data is available, for instance when benchmarking a new protein-ligand set, we would like to compare how well FEP is predicting with respect to these data.    \n",
    "\n",
    "First, we want to set the file paths to our results and experimental data. We also want to create a list of the perturbations and of ligands so we can use/edit these throughout the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected network\n",
    "# we will define the engine here for ease\n",
    "engine = \"SOMD\"\n",
    "\n",
    "# experimental values (e.g. ic50/ki) for all ligands in our set.\n",
    "exp_filepath = \"analysis/exp_data_tyk2.dat\"\n",
    "\n",
    "# We also want to create a list of the perturbations in our network.\n",
    "# create a list of the perturbations\n",
    "perturbations = []\n",
    "\n",
    "# create a list of ligands\n",
    "ligands = []\n",
    "\n",
    "# use the network file to find the ligands and perturbations\n",
    "for line in open(\"analysis/network_lomap.dat\", \"r\"):\n",
    "    lig_0 = line.split()[0]\n",
    "    lig_1 = line.split()[1]\n",
    "    pert = f\"{lig_0}~{lig_1}\"\n",
    "    perturbations.append(pert)\n",
    "    if lig_0 not in ligands:\n",
    "        ligands.append(lig_0)\n",
    "    elif lig_1 not in ligands:\n",
    "        ligands.append(lig_1)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# make a directory for all our output files\n",
    "if not os.path.exists(\"analysis/outputs\"):\n",
    "    os.mkdir(\"analysis/outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to how we used NetworkX in the setup to visualise our adjusted network, we can also use it here to view the network we are analysing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the graph.\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Loop over the nligands and add as nodes to the graph.\n",
    "for lig in ligands:\n",
    "    graph.add_node(lig, label=lig, labelloc=\"t\")\n",
    "\n",
    "# Loop over the edges in the dictionary and add to the graph.\n",
    "for edge in perturbations:\n",
    "    lig_0 = edge.split(\"~\")[0]\n",
    "    lig_1 = edge.split(\"~\")[1]\n",
    "    graph.add_edge(lig_0, lig_1)\n",
    "\n",
    "# Plot the networkX graph.\n",
    "pos = nx.kamada_kawai_layout(graph)\n",
    "plt.figure(figsize=(8, 8), dpi=150)\n",
    "nx.draw(\n",
    "    graph,\n",
    "    pos,\n",
    "    edge_color=\"black\",\n",
    "    width=1,\n",
    "    linewidths=1,\n",
    "    node_size=1800,\n",
    "    node_color=\"skyblue\",\n",
    "    font_size=12,\n",
    "    labels={node: node for node in graph.nodes()},\n",
    ")\n",
    "\n",
    "plt.savefig(\"analysis/outputs/analysis_network.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the network that we are considering, we want to get results files with these perturbations from the overall file that contains the large network results. We do not usually have to do this, but in this case it is neccessary to get the files that we need for analysis later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_all_files = []\n",
    "no_repeats = 3\n",
    "# create a list of the results files\n",
    "for r in list(range(0, no_repeats)):\n",
    "    file_name = f\"analysis/freenrg_repeat_{r}_tyk2.csv\"\n",
    "    results_all_files.append(file_name)\n",
    "\n",
    "results_files = []\n",
    "\n",
    "for file in results_all_files:\n",
    "    new_file_name = f\"analysis/outputs/results_{results_all_files.index(file)}.csv\"\n",
    "    with open(new_file_name, \"w\") as result_file:\n",
    "        writer = csv.writer(result_file, delimiter=\",\")\n",
    "        writer.writerow([\"lig_1\", \"lig_2\", \"freenrg(kcal/mol)\", \"error(kcal/mol)\", \"engine\"])\n",
    "\n",
    "        for row, index in pd.read_csv(file).iterrows():\n",
    "            pert = f\"{index['lig_1']}~{index['lig_2']}\"\n",
    "            if pert in perturbations:\n",
    "                writer.writerow(\n",
    "                    [\n",
    "                        index[\"lig_1\"],\n",
    "                        index[\"lig_2\"],\n",
    "                        index[\"freenrg(kcal/mol)\"],\n",
    "                        index[\"error(kcal/mol)\"],\n",
    "                        index[\"engine\"],\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        results_files.append(new_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Analysing repeats\n",
    "<a id=\"reps\"></a>  \n",
    "\n",
    "For the first analysis, we will look at the reproducibility between different repeats. We will calculate the average and SEM for the computed runs, based on their repeats. Here, we have six repeats for each. The SEM can be useful to see how reproducible the different runs are, and a larger SEM would indicate a perturbation that has poorer convergence between repeats.   \n",
    "\n",
    "In general, for our analyses, we will create a dictionary of the values. These can then be easily converted into a pandas dataframe for plotting. It is also a good idea to save output csv files, so that these are easily accessible in the future and can be loaded into python/excel again for any other plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary with the results of the files\n",
    "comp_dict_list = {}\n",
    "\n",
    "# append for results file\n",
    "for res_file in results_files:\n",
    "    res_df = pd.read_csv(res_file)\n",
    "    for index, row in res_df.iterrows():\n",
    "        lig_0 = row[0]\n",
    "        lig_1 = row[1]\n",
    "        pert = f\"{lig_0}~{lig_1}\"\n",
    "        # if not comp_dict_list[pert]:\n",
    "        #     print(\"oop\")\n",
    "        ddG = row[2]\n",
    "\n",
    "        if pert in comp_dict_list:\n",
    "            # Key exist in dict, check if is a list\n",
    "            if not isinstance(comp_dict_list[pert], list):\n",
    "                # If type is not list then make it list\n",
    "                comp_dict_list[pert] = [comp_dict_list[pert]]\n",
    "            # Append the value in list\n",
    "            comp_dict_list[pert].append(ddG)\n",
    "        else:\n",
    "            # As key is not in dict,\n",
    "            # so, add key-value pair\n",
    "            comp_dict_list[pert] = ddG\n",
    "\n",
    "# now calculate all the avg and SEM for the network perturbations\n",
    "# put these into a dictionary\n",
    "comp_diff_dict = {}\n",
    "\n",
    "# write these to a csv file\n",
    "with open(\"analysis/outputs/computed_perturbations_average.csv\", \"w\") as comp_pert_file:\n",
    "    writer = csv.writer(comp_pert_file, delimiter=\",\")\n",
    "    writer.writerow([\"lig_1\", \"lig_2\", \"freenrg(kcal/mol)\", \"error(kcal/mol)\", \"engine\"])\n",
    "    for pert in perturbations:\n",
    "        ddGs = comp_dict_list[pert]\n",
    "        lig_0 = pert.split(\"~\")[0]\n",
    "        lig_1 = pert.split(\"~\")[1]\n",
    "        comp_ddG = np.average(ddGs)\n",
    "        comp_err = sem(ddGs)\n",
    "\n",
    "        # update the dictionary for plotting later\n",
    "        comp_diff_dict.update({pert: (comp_ddG, comp_err)})\n",
    "\n",
    "        writer.writerow([lig_0, lig_1, comp_ddG, comp_err, engine])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Experimental binding affinities\n",
    "\n",
    "Next, we want to visualise our results whilst comparing them to experimental values. In this example here, TYK2 has binding affinities in Ki, and can be converted using ΔG = RTlnK . It is important at this stage to make sure that the units match, so they are consequently converted into kcal/mol. We can carry this conversion out like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary for the experimental values\n",
    "exper_val_dict = {}\n",
    "\n",
    "# set the temperature in Kelvin\n",
    "temp = 300\n",
    "\n",
    "with open(exp_filepath, \"r\") as exp_file:\n",
    "    for line in exp_file:\n",
    "        lig = line.split(\",\")[0]\n",
    "        if lig != \"lig\":\n",
    "            exp_val = line.split(\",\")[1].strip()\n",
    "        if exp_val != \"value\":\n",
    "            exp_val = float(exp_val)\n",
    "            # gas constant in kcal per Kelvin per mol, exp val converted into M\n",
    "            exp_kcal = 0.0019872041 * temp * np.log(exp_val / (10 ^ 9))\n",
    "        err = line.split(\",\")[2].strip()\n",
    "        if err != \"error\":\n",
    "            err = float(err)\n",
    "            # get the upper and lower values for the error\n",
    "            exp_upper = exp_val + err\n",
    "            exp_lower = exp_val - err\n",
    "            exp_upper_kcal = 0.0019872041 * temp * np.log(exp_upper / (10 ^ 9))\n",
    "            exp_lower_kcal = 0.0019872041 * temp * np.log(exp_lower / (10 ^ 9))\n",
    "            err_kcal = abs(exp_upper_kcal - exp_lower_kcal) / 2\n",
    "            exper_val_dict.update({lig: (exp_kcal, err_kcal)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have our dictionary,\n",
    "# we can also create a dictionary with all the experimental values for the perturbations\n",
    "exper_diff_dict = {}\n",
    "\n",
    "# calculate the experimental RBFEs\n",
    "# write these to a csv file\n",
    "with open(\"analysis/outputs/experimental_perturbations.csv\", \"w\") as exp_pert_file:\n",
    "    writer = csv.writer(exp_pert_file, delimiter=\",\")\n",
    "    writer.writerow([\"lig_1\", \"lig_2\", \"freenrg(kcal/mol)\", \"error(kcal/mol)\", \"engine\"])\n",
    "\n",
    "    for pert in perturbations:\n",
    "        lig_0 = pert.split(\"~\")[0]\n",
    "        lig_1 = pert.split(\"~\")[1]\n",
    "        exper_ddG = exper_val_dict[lig_1][0] - exper_val_dict[lig_0][0]\n",
    "        exper_err = math.sqrt(\n",
    "            math.pow(exper_val_dict[lig_0][1], 2)\n",
    "            + math.pow(exper_val_dict[lig_1][1], 2)\n",
    "        )\n",
    "        exper_diff_dict.update({pert: (exper_ddG, exper_err)})\n",
    "\n",
    "        writer.writerow([lig_0, lig_1, exper_ddG, exper_err, \"experimental\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Plotting\n",
    "<a id=\"plot\"></a>\n",
    "\n",
    "Now we have our computational and experimental in dicitonary format, we can turn this into a pandas dataframe. For plotting it is typically easier to work with the pandas library, which is why this next piece of code will reshape it to this.   \n",
    "\n",
    "Note that if pandas returns value errors at this step, it is likely there are ligands missing from either your FEP outputs or your experimental input. If a single repeat of a perturbation is missing, the code should be able to deal with this, but if a whole perturbation from the network file is missing there should be an error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freenrg_pert_dict = {}\n",
    "\n",
    "# construct dict with experimental freenrg and error and computed\n",
    "for pert in perturbations:\n",
    "    exp_ddG = exper_diff_dict[pert][0]\n",
    "    exp_err = exper_diff_dict[pert][1]\n",
    "    comp_ddG = comp_diff_dict[pert][0]\n",
    "    comp_err = comp_diff_dict[pert][1]\n",
    "    freenrg_pert_dict[pert] = [exp_ddG, exp_err, comp_ddG, comp_err]\n",
    "\n",
    "# want to put these in a joint dictionary so can convert into pandas df\n",
    "freenrg_df_pert = pd.DataFrame(\n",
    "    freenrg_pert_dict, index=[\"freenrg_exp\", \"err_exp\", \"freenrg_fep\", \"err_fep\"]\n",
    ").transpose()\n",
    "\n",
    "# save our results to a file that can be opened in e.g. Excel.\n",
    "freenrg_df_pert.to_csv(\"analysis/outputs/fep_diff_results_table.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can plot our results against the experimental data. This is best done using a scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a scatter plot\n",
    "plt.rc(\"font\", size=12)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# get these based on which column the data is in.\n",
    "x = freenrg_df_pert[\"freenrg_exp\"]\n",
    "y = freenrg_df_pert[\"freenrg_fep\"]\n",
    "x_er = freenrg_df_pert[\"err_exp\"]\n",
    "y_er = freenrg_df_pert[\"err_fep\"]\n",
    "\n",
    "# plotting the scatterplot\n",
    "scatterplot = [plt.scatter(x, y, zorder=10)]\n",
    "\n",
    "# plotting error bars\n",
    "plt.errorbar(\n",
    "    x,\n",
    "    y,\n",
    "    yerr=y_er,\n",
    "    # xerr=x_er,   # comment this line to hide experimental error bars \\\n",
    "    # as this can sometimes overcrowd the plot.\n",
    "    ls=\"none\",\n",
    "    lw=0.5,\n",
    "    capsize=2,\n",
    "    color=\"black\",\n",
    "    zorder=5,\n",
    ")\n",
    "\n",
    "# plot 1/2 kcal bounds:\n",
    "plt.fill_between(\n",
    "    x=[-100, 100],\n",
    "    y2=[-100.25, 99.75],\n",
    "    y1=[-99.75, 100.25],\n",
    "    lw=0,\n",
    "    zorder=-10,\n",
    "    alpha=0.3,\n",
    "    color=\"grey\",\n",
    ")\n",
    "# upper bound:\n",
    "plt.fill_between(\n",
    "    x=[-100, 100],\n",
    "    y2=[-99.5, 100.5],\n",
    "    y1=[-99.75, 100.25],\n",
    "    lw=0,\n",
    "    zorder=-10,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "# lower bound:\n",
    "plt.fill_between(\n",
    "    x=[-100, 100],\n",
    "    y2=[-100.25, 99.75],\n",
    "    y1=[-100.5, 99.5],\n",
    "    lw=0,\n",
    "    zorder=-10,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    ")\n",
    "\n",
    "# get the bounds. This can be done with min/max or simply by hand.\n",
    "all_freenrg_values = np.concatenate(\n",
    "    [freenrg_df_pert[\"freenrg_exp\"].values, freenrg_df_pert[\"freenrg_fep\"].values]\n",
    ")\n",
    "min_lim = min(all_freenrg_values)\n",
    "max_lim = max(all_freenrg_values)\n",
    "\n",
    "# for a scatterplot we want the axis ranges to be the same.\n",
    "plt.xlim(min_lim * 1.3, max_lim * 1.3)\n",
    "plt.ylim(min_lim * 1.3, max_lim * 1.3)\n",
    "\n",
    "plt.axhline(color=\"black\", zorder=1)\n",
    "plt.axvline(color=\"black\", zorder=1)\n",
    "\n",
    "plt.ylabel(\"Computed $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "plt.xlabel(\"Experimental $\\Delta\\Delta$G$_{bind}$ / kcal$\\cdot$mol$^{-1}$\")\n",
    "\n",
    "plt.savefig(\"analysis/outputs/fep_vs_exp_scatterplot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very simple way to initially visualise our results. Below, we will consider more rigorous methods for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Network Analysis using Cinnabar\n",
    "<a id=\"cinnabar\"></a>\n",
    "\n",
    "Instead of just computing ΔΔG values for each transformation, we would like to estimate the ΔΔG value for each individual ligand. There are some involved algorithms needed for these steps, and in this section of the tutorial, we will be using [cinnabar](https://github.com/OpenFreeEnergy/cinnabar) to care of that for us. This already has all the analysis and plotting in functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cinnabar import wrangle, plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a csv file\n",
    "with open(f\"analysis/outputs/cinnabar_data.csv\", \"w\") as cinnabar_data_file:\n",
    "    writer = csv.writer(cinnabar_data_file, delimiter=\",\")\n",
    "\n",
    "    # first, write the experimental data\n",
    "    writer.writerow([\"# Experimental block\"])\n",
    "    writer.writerow([\"# Ligand\", \"expt_DDG\", \"expt_dDDG\"])\n",
    "\n",
    "    for lig in exper_val_dict.keys():\n",
    "        writer.writerow([lig, f\"{exper_val_dict[lig][0]}\", f\"{exper_val_dict[lig][1]}\"])\n",
    "\n",
    "    # second write the perturbation data\n",
    "    writer.writerow([\" \"])\n",
    "    writer.writerow([\"# Calculated block\"])\n",
    "    writer.writerow(\n",
    "        [\"# Ligand1\", \"Ligand2\", \"calc_DDG\", \"calc_dDDG(MBAR)\", \"calc_dDDG(additional)\"]\n",
    "    )\n",
    "\n",
    "    # need to write the average of the data, otherwise cinnabar just uses the last entry\n",
    "    comp_diff_dict = {}\n",
    "\n",
    "    # make a dictionary with the results of the files\n",
    "    comp_dict_list = {}\n",
    "    comp_err_dict_list = {}\n",
    "\n",
    "    # append for results file\n",
    "    for res_file in results_files:\n",
    "        res_df = pd.read_csv(res_file)\n",
    "        for index, row in res_df.iterrows():\n",
    "            lig_0 = row[0]\n",
    "            lig_1 = row[1]\n",
    "            pert = f\"{lig_0}~{lig_1}\"\n",
    "            ddG = float(row[2])\n",
    "            ddG_err = float(row[3])\n",
    "\n",
    "            if pert in comp_dict_list:\n",
    "                # Key exist in dict, check if is a list\n",
    "                if not isinstance(comp_dict_list[pert], list):\n",
    "                    # If type is not list then make it list\n",
    "                    comp_dict_list[pert] = [comp_dict_list[pert]]\n",
    "                if not isinstance(comp_err_dict_list[pert], list):\n",
    "                    # If type is not list then make it list\n",
    "                    comp_err_dict_list[pert] = [comp_err_dict_list[pert]]\n",
    "                # Append the value in list\n",
    "                comp_dict_list[pert].append(ddG)\n",
    "                comp_err_dict_list[pert].append(ddG_err)\n",
    "            else:\n",
    "                # As key is not in dict,\n",
    "                # so, add key-value pair\n",
    "                comp_dict_list[pert] = [ddG]\n",
    "                comp_err_dict_list[pert] = [ddG_err]\n",
    "\n",
    "    # now calculate all the avg and SEM for the network perturbations\n",
    "    for pert in perturbations:\n",
    "        lig_0 = pert.split(\"~\")[0]\n",
    "        lig_1 = pert.split(\"~\")[1]\n",
    "\n",
    "        # check if the perturbations calculated are also those in the network file and if any are missing\n",
    "        try:\n",
    "            # find the values in the dictionary\n",
    "            ddGs = comp_dict_list[pert]\n",
    "            ddGs_error = comp_err_dict_list[pert]\n",
    "            # calculate the average and the error\n",
    "            comp_ddG = np.average(ddGs)\n",
    "            # comp_ddG = np.average([ddG.value() for ddG in ddGs])\n",
    "            if len(ddGs) == 1:\n",
    "                comp_err = ddGs_error[0]\n",
    "                # comp_err = ddGs_error.value()\n",
    "            else:\n",
    "                comp_err = sem(ddGs)\n",
    "                # comp_err = sem([ddG.value() for ddG in ddGs])\n",
    "\n",
    "        # if unable to calculate one of the perturbations, this is a None value.\n",
    "        except:\n",
    "            comp_ddG = None\n",
    "            comp_err = None\n",
    "\n",
    "        # update the dictionary\n",
    "        comp_diff_dict.update({pert: (comp_ddG, comp_err)})\n",
    "\n",
    "    # write to file\n",
    "    for key in comp_diff_dict:\n",
    "        lig_0 = key.split(\"~\")[0]\n",
    "        lig_1 = key.split(\"~\")[1]\n",
    "        comp_ddG = comp_diff_dict[key][0]\n",
    "        comp_err = comp_diff_dict[key][1]\n",
    "\n",
    "        if not comp_ddG:\n",
    "            pass\n",
    "        else:\n",
    "            pert = f\"{lig_0}~{lig_1}\"\n",
    "            if pert in perturbations:\n",
    "                writer.writerow([lig_0, lig_1, comp_ddG, comp_err, \"0.0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use this file to instatiate a FEMap object, that we can then use to plot both the perturbations and also the analysis per ligand. These plots also return the statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = wrangle.FEMap(f\"analysis/outputs/cinnabar_data.csv\")\n",
    "# plot the perturbations\n",
    "plotting.plot_DDGs(network.graph, title=\"DDGs\", filename=f\"analysis/outputs/DDGs.png\", figsize=6)\n",
    "# plot the ligands\n",
    "plotting.plot_DGs(network.graph, title=\"DGs\", filename=f\"analysis/outputs/DGs.png\", figsize=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Outliers\n",
    "<a id=\"outliers\"></a>\n",
    "In a network analysis, a badly computed perturbation can impact the overall quality of our network. Below, we want to annotate any outliers for our perturbations (on the scatter plot) so we can exclude them, rerun  our network analysis, and improve this. We can do this in one of two ways - either we can remove the values that disagree more substantially with the experimental, as below, or, if no experimental values are available, we can consider the error of the perturbation.\n",
    "\n",
    "First, let's look at our scatter plot with the outlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_outliers_to_annotate = 3\n",
    "\n",
    "# get an array of the MUE values comparing experimental and FEP values. Take the absolute values.\n",
    "mue_values = abs(freenrg_df_pert[\"freenrg_exp\"] - freenrg_df_pert[\"freenrg_fep\"])\n",
    "\n",
    "# find the n ligand names that are outliers.\n",
    "outlier_names = mue_values.nlargest(number_outliers_to_annotate).index.values.tolist()\n",
    "print(outlier_names)\n",
    "\n",
    "# construct a list of labels to annotate the scatterplot with.\n",
    "annot_labels = []\n",
    "colours = []\n",
    "for ligand in freenrg_df_pert.index.values:\n",
    "    # if the ligand is an outlier, append the name to the annotation labels list.\n",
    "    if ligand in outlier_names:\n",
    "        annot_labels.append(ligand)\n",
    "        colours.append(\"red\")\n",
    "    else:\n",
    "        # if the ligand is not an outlier, append an empty string to the annotation labels list.\n",
    "        annot_labels.append(\"\")\n",
    "        colours.append(\"blue\")\n",
    "\n",
    "# Create the same scatterplot as above. Can include some more of the formatting if needed.\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "plt.scatter(\n",
    "    freenrg_df_pert[\"freenrg_exp\"], freenrg_df_pert[\"freenrg_fep\"], zorder=10, c=colours\n",
    ")\n",
    "plt.plot((-10, 10), (-10, 10))\n",
    "plt.xlim(min_lim * 1.3, max_lim * 1.3)\n",
    "plt.ylim(min_lim * 1.3, max_lim * 1.3)\n",
    "\n",
    "# then, after generating the figure, we can annotate:\n",
    "for i, txt in enumerate(annot_labels):\n",
    "    plt.annotate(\n",
    "        txt,\n",
    "        (\n",
    "            freenrg_df_pert[\"freenrg_exp\"].values.tolist()[i] + 0.1,  # x coords\n",
    "            freenrg_df_pert[\"freenrg_fep\"].values.tolist()[i] + 0.1,\n",
    "        ),  # y coords\n",
    "        size=20,\n",
    "        color=\"crimson\",\n",
    "    )\n",
    "\n",
    "plt.savefig(\"analysis/outputs/fep_vs_exp_outlier_plot.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_table = pd.DataFrame(freenrg_df_pert[\"err_fep\"]).sort_values(by=\"err_fep\")\n",
    "\n",
    "# we can write the table to a csv file that can be opened in e.g. Excel.\n",
    "error_table.to_csv(\"analysis/outputs/error_table.csv\")\n",
    "error_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Exercise 2.1.1: Excluding intermediates from the Network analysis</b>\n",
    "</div>\n",
    "\n",
    "Try exculding this perturbation and rerunning the above Network analysis. First, we need to remove the perturbation. Then, we need to make sure that our new output image is being saved using a different file path. Adjust these in the cells below where the #FIXME is.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the perturbation\n",
    "# FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary {style='color:green;font-weight:bold'}> Click here to see solution to Exercise. </summary>\n",
    "\n",
    "```python\n",
    "perturbations.remove(\"lig_ejm42~lig_ejm49\")\n",
    "perturbations.remove(\"lig_ejm44~lig_ejm45\")\n",
    "perturbations.remove(\"lig_ejm31~lig_ejm49\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerun the above cells for network analysis with a new file path\n",
    "# FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary {style='color:green;font-weight:bold'}> Click here to see solution to Exercise. </summary>\n",
    "\n",
    "```python\n",
    "# write to a csv file\n",
    "with open(f\"analysis/outputs/cinnabar_data_outliers_removed.csv\", \"w\") as cinnabar_data_file:\n",
    "    writer = csv.writer(cinnabar_data_file, delimiter=\",\")\n",
    "\n",
    "    # first, write the experimental data\n",
    "    writer.writerow([\"# Experimental block\"])\n",
    "    writer.writerow([\"# Ligand\",\"expt_DDG\",\"expt_dDDG\"])\n",
    "\n",
    "    for lig in exper_val_dict.keys():\n",
    "        writer.writerow([lig,f\"{exper_val_dict[lig][0]}\",f\"{exper_val_dict[lig][1]}\"])\n",
    "\n",
    "\n",
    "    # second write the perturbation data\n",
    "    writer.writerow([\" \"])\n",
    "    writer.writerow([\"# Calculated block\"])\n",
    "    writer.writerow([\"# Ligand1\",\"Ligand2\",\"calc_DDG\",\"calc_dDDG(MBAR)\", \"calc_dDDG(additional)\"])\n",
    "\n",
    "    # need to write the average of the data, otherwise cinnabar just uses the last entry\n",
    "    comp_diff_dict = {}\n",
    "\n",
    "    # make a dictionary with the results of the files\n",
    "    comp_dict_list = {}\n",
    "    comp_err_dict_list = {}\n",
    "\n",
    "    # append for results file\n",
    "    for res_file in results_files:\n",
    "        res_df = pd.read_csv(res_file)\n",
    "        for index,row in res_df.iterrows():\n",
    "\n",
    "            lig_0 = row[0]\n",
    "            lig_1 = row[1]\n",
    "            pert = f\"{lig_0}~{lig_1}\"\n",
    "            ddG = float(row[2])\n",
    "            ddG_err = float(row[3])\n",
    "                \n",
    "            if pert in comp_dict_list:\n",
    "                # Key exist in dict, check if is a list\n",
    "                if not isinstance(comp_dict_list[pert], list):\n",
    "                    # If type is not list then make it list\n",
    "                    comp_dict_list[pert] = [comp_dict_list[pert]]\n",
    "                if not isinstance(comp_err_dict_list[pert], list):\n",
    "                    # If type is not list then make it list\n",
    "                    comp_err_dict_list[pert] = [comp_err_dict_list[pert]]\n",
    "                # Append the value in list\n",
    "                comp_dict_list[pert].append(ddG)\n",
    "                comp_err_dict_list[pert].append(ddG_err)\n",
    "            else:\n",
    "                # As key is not in dict,\n",
    "                # so, add key-value pair\n",
    "                comp_dict_list[pert] = [ddG]\n",
    "                comp_err_dict_list[pert] = [ddG_err]\n",
    "\n",
    "    # now calculate all the avg and SEM for the network perturbations  \n",
    "    for pert in perturbations:\n",
    "        lig_0 = pert.split(\"~\")[0]\n",
    "        lig_1 = pert.split(\"~\")[1]\n",
    "        \n",
    "        # check if the perturbations calculated are also those in the network file and if any are missing\n",
    "        try:\n",
    "            # find the values in the dictionary\n",
    "            ddGs = comp_dict_list[pert]\n",
    "            ddGs_error = comp_err_dict_list[pert]\n",
    "            # calculate the average and the error\n",
    "            comp_ddG = np.average(ddGs)\n",
    "            # comp_ddG = np.average([ddG.value() for ddG in ddGs])\n",
    "            if len(ddGs) == 1:\n",
    "                comp_err = ddGs_error[0]\n",
    "                # comp_err = ddGs_error.value()\n",
    "            else:\n",
    "                comp_err = sem(ddGs)\n",
    "                # comp_err = sem([ddG.value() for ddG in ddGs])\n",
    "    \n",
    "        # if unable to calculate one of the perturbations, this is a None value.\n",
    "        except:\n",
    "            comp_ddG = None\n",
    "            comp_err = None\n",
    "\n",
    "        #update the dictionary\n",
    "        comp_diff_dict.update({pert:(comp_ddG, comp_err)})\n",
    "\n",
    "    # write to file\n",
    "    for key in comp_diff_dict:\n",
    "        lig_0 = key.split(\"~\")[0]\n",
    "        lig_1 = key.split(\"~\")[1]\n",
    "        comp_ddG = comp_diff_dict[key][0]\n",
    "        comp_err = comp_diff_dict[key][1]            \n",
    "\n",
    "        if not comp_ddG:\n",
    "            pass\n",
    "        else:\n",
    "            pert = f\"{lig_0}~{lig_1}\"\n",
    "            if pert in perturbations:\n",
    "                writer.writerow([lig_0, lig_1, comp_ddG, comp_err, \"0.0\"])\n",
    "\n",
    "network = wrangle.FEMap(f\"analysis/outputs/cinnabar_data_outliers_removed.csv\")\n",
    "# plot the perturbations\n",
    "plotting.plot_DDGs(network.graph, title=\"DDGs\", filename=f\"analysis/outputs/DDGs_outliers_removed.png\", figsize=6)\n",
    "# plot the ligands\n",
    "plotting.plot_DGs(network.graph, title=\"DGs\", filename=f\"analysis/outputs/DGs_outliers_removed.png\", figsize=6)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, removing perturbations is not always a good idea, especially if we do not have very large outliers as is the case here. As can be seen in the sample output folder, when we remove [three of the perturbations](example_output/example_output_analysis/DGs_three_outliers_removed.png), we loose one of the ligands in our network (N=16). Removing only [one perturbation](example_output/example_output_analysis/DGs_three_outliers_removed.png) does not improve our statistics either. Generally, removing perturbations should only be done after very careful consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Visualising the ligand\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>Exercise 2.2.1: Visualising the ligand</b>\n",
    "</div>\n",
    "\n",
    "Based on our results, we may also want to visualise which of our ligands had the highest binding affinity.\n",
    "\n",
    "**Hint:** First, obtain the node information from the cinnabar graph. Sort this resulting data frame to find the ligand with the best binding affinity and then use BSS to visualise it like in the introductionary workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary {style='color:green;font-weight:bold'}> Click here to see solution to Exercise. </summary>\n",
    "\n",
    "```python\n",
    "\n",
    "lig_dict = {entry[1]['name']:entry[1]['calc_DG'] for entry in network.graph.nodes.data()}\n",
    "lig_df = pd.DataFrame.from_dict(lig_dict, orient=\"index\", columns=[\"calc_DG\"])\n",
    "lig_df.to_csv(\"analysis/outputs/ligand_calc_DG.csv\")\n",
    "lig_df.sort_values(\"calc_DG\")\n",
    "\n",
    "```\n",
    "\n",
    "The best binder based on this data is 'lig_jmc27'. We can visualise this using BSS:\n",
    "\n",
    "```python\n",
    "\n",
    "BSS.Notebook.View(\"inputs/ligands/analysis_ligands/jmc_27.sdf\").system()\n",
    "\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Congratulations\n",
    "You have made it to the end! This notebook has covered the basics of some analysis that can be done on our RBFE results. There are many ways to customise this, and it is also a good idea to check out the further reading for a good overview of AFE data reporting best practices: [Section 8.7, LiveComs Best Practices for Alchemical Free Energy Calculations](https://livecomsjournal.org/index.php/livecoms/article/view/v2i1e18378).\n",
    "\n",
    "As for the setup workshop, all the generated graphs and tables outputs are available in the 'example_output' folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to download example outputs\n",
    "# download(\"03\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "d79bb85316fa6c998e385cc39903e056bffeb3f6098416e9c269ddd32175e919"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
